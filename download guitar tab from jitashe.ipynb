{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取所有专辑歌曲URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cookielib\n",
    "import urllib2\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "from bs4 import *\n",
    "import re\n",
    "\n",
    "\n",
    "BASE_URL = 'http://www.jitashe.net'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_soup(url):  \n",
    "    try:\n",
    "        response = urllib2.urlopen(baseUrl,timeout=10)  # 请求网页，返回句柄\n",
    "        page = response.read()  # 读取并返回网页内容\n",
    "        # print 'open !!!'    \n",
    "        soup = BeautifulSoup(page)\n",
    "        return soup\n",
    "\n",
    "    except Exception, e:\n",
    "        print e\n",
    "        print url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wybert\\Anaconda2\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': u'\\u518d\\u4e5f\\u4e0d\\u4f1a\\u53bb\\u4e3d\\u6c5f',\n",
       "  'url': 'http://www.jitashe.net/album/2100205356/'},\n",
       " {'name': u'\\u5409\\u59c6\\u9910\\u5385',\n",
       "  'url': 'http://www.jitashe.net/album/2013969781/'},\n",
       " {'name': u'\\u8d75\\u5c0f\\u96f7',\n",
       "  'url': 'http://www.jitashe.net/album/465009/'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_all_alblum_name(soup):\n",
    "    \n",
    "    album_list=[]\n",
    "    albumlist = soup.findAll('a',{'class':'CDcover100'})\n",
    "    for album_li in albumlist:\n",
    "        album={}\n",
    "        album['url']= BASE_URL + album_li['href']\n",
    "        album['name'] = album_li['title']\n",
    "        album_list += [album]   \n",
    "        \n",
    "    return album_list\n",
    "\n",
    "baseUrl = 'http://www.jitashe.net/album/list/4447'\n",
    "soup= get_soup(baseUrl)\n",
    "album_list =  find_all_alblum_name(soup)\n",
    "album_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_song_url(url):\n",
    "    \n",
    "    song_list = []\n",
    "    \n",
    "    response = urllib2.urlopen(url,timeout=10)  # 请求网页，返回句柄\n",
    "    page = response.read()  # 读取并返回网页内容\n",
    "    \n",
    "    regular = r'''<div class='song_info'>[\\s\\S]{10,300}</div>'''\n",
    "    pattern = re.compile(regular)\n",
    "    \n",
    "    song_div_list = pattern.findall(page)\n",
    "    for song in song_div_list:   \n",
    "        asong={}\n",
    "        soup = BeautifulSoup(song)\n",
    "        song = soup.find('a')\n",
    "        asong['url']=BASE_URL + song['href']\n",
    "        asong['name']=song.text\n",
    "        song_list +=[asong]\n",
    "    return song_list\n",
    "\n",
    "URL_LIST=[]\n",
    "\n",
    "for item  in album_list:\n",
    "    url = item['url']\n",
    "#     print url\n",
    "    temp={}\n",
    "    song_list = find_song_url(url)\n",
    "    temp['album']= item['name']\n",
    "    temp['datial']=song_list\n",
    "    URL_LIST+=[temp]\n",
    "#     brebak\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取吉他谱URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_tab_url(url):\n",
    "    tab_list = []\n",
    "    \n",
    "    response = urllib2.urlopen(url,timeout=10)  # 请求网页，返回句柄\n",
    "    page = response.read()  # 读取并返回网页内容\n",
    "\n",
    "    regular = r'''<div class=\"bm_c tablist\">[\\s\\S]*<div class=\"bm\" id=\"songvideo\">'''\n",
    "\n",
    "    pattern = re.compile(regular)\n",
    "    tab_div = pattern.findall(page)[0].strip('''<div class=\"bm\" id=\"songvideo\">''')\n",
    "    tab_div = BeautifulSoup(tab_div) \n",
    "    tablist = tab_div.findAll('a',{'class':'xst'})\n",
    "    tab_type = tab_div.findAll('img')\n",
    "#     print tab_type\n",
    "    for item,type_ in zip(tablist,tab_type):\n",
    "        tab={}\n",
    "        tab['url'] = BASE_URL+item['href']\n",
    "        tab['type'] = type_['title']\n",
    "        tab_list += [tab]        \n",
    "    return tab_list\n",
    "\n",
    "def get_img_url(url):\n",
    "    img_list = []\n",
    "    \n",
    "    response = urllib2.urlopen(url,timeout=10)  # 请求网页，返回句柄\n",
    "    page = response.read()  # 读取并返回网页内容\n",
    "\n",
    "    regular = r'''<div class=\"imgtab\">[\\s\\S]*<a name=\"forDownload\" id=\"forDownload\"></a>'''\n",
    "    pattern = re.compile(regular)\n",
    "    img_div = pattern.findall(page)[0].strip('''<a name=\"forDownload\" id=\"forDownload\"></a>''')\n",
    "    img_div = BeautifulSoup(img_div) \n",
    "    imglist = img_div.findAll('img')\n",
    "    for item in imglist:\n",
    "#         print item\n",
    "        img={}\n",
    "        img['url'] = BASE_URL+'/'+item['file']\n",
    "        img_list += [img]\n",
    "        \n",
    "    return img_list\n",
    "'''\n",
    "抓取网页文件内容，保存到内存\n",
    "\n",
    "@url 欲抓取文件 ，path+filename\n",
    "'''\n",
    "def get_file(url):\n",
    "    try:\n",
    "        response = urllib2.urlopen(url,timeout=10)  # 请求网页，返回句柄\n",
    "        data=response.read()\n",
    "        return data\n",
    "    except BaseException, e:\n",
    "        print e\n",
    "        return None\n",
    "    \n",
    "'''\n",
    "保存文件到本地\n",
    "\n",
    "@path  本地路径\n",
    "@file_name 文件名\n",
    "@data 文件内容\n",
    "'''\n",
    "from os import mkdir\n",
    "def save_file(path, file_name, data):\n",
    "    if data == None:\n",
    "        return\n",
    "    \n",
    "    if(not path.endswith(\"/\")):\n",
    "        path=path+\"/\"\n",
    "    file=open(path+file_name, \"wb\")\n",
    "    file.write(data)\n",
    "    file.flush()\n",
    "    file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def download_asong_tab(song_album,song_name,song_url):\n",
    "    tab_url = get_tab_url(song_url)\n",
    "    for j,item in enumerate(tab_url):\n",
    "        if item['type'] !=u'图片谱':\n",
    "            continue\n",
    "        imgurl = item['url']\n",
    "        img = get_img_url(imgurl)\n",
    "        for i,jpg_url in enumerate(img):\n",
    "            file_data = get_file(jpg_url['url'][:-10]) \n",
    "            file_name=song_name+u'版本'+str(j+1)+'_'+str(i+1)+'.jpg'\n",
    "            save_file(song_album, file_name, file_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for item in album_list:\n",
    "    mkdir(item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取专辑 赵小雷\n",
      "**********\n",
      "人家\n",
      "list index out of range\n",
      "未给姐姐递出的信\n",
      "list index out of range\n",
      "çť\n",
      "不开的唇\n",
      "赵小雷\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "HTTP Error 404: Not Found\n",
      "南方姑娘\n",
      "list index out of range\n",
      "Over\n",
      "list index out of range\n",
      "开往北京的火车\n",
      "list index out of range\n",
      "背影\n",
      "list index out of range\n",
      "妈妈\n",
      "南方姑娘 (弹唱版)\n",
      "list index out of range\n",
      "民谣\n",
      "list index out of range\n"
     ]
    }
   ],
   "source": [
    "for item in URL_LIST[-1:]:\n",
    "    print '获取专辑',item['album']\n",
    "    print '*'*10\n",
    "    song_album=item['album']\n",
    "    \n",
    "    for song in item['datial']:\n",
    "        song_name=song['name']\n",
    "        song_url=song['url']\n",
    "        try:\n",
    "            print song_name\n",
    "            download_asong_tab(song_album,song_name,song_url)\n",
    "        except Exception,e:\n",
    "            print e \n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'album': u'\\u518d\\u4e5f\\u4e0d\\u4f1a\\u53bb\\u4e3d\\u6c5f',\n",
       " 'datial': [{'name': u'\\u518d\\u4e5f\\u4e0d\\u4f1a\\u53bb\\u4e3d\\u6c5f',\n",
       "   'url': 'http://www.jitashe.net/song/1774824066/'}]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL_LIST[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filehander = open('test.txt','w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filehander.write('sjhd')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
